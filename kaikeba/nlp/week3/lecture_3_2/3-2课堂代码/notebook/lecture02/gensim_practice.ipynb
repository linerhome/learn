{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. gensim实践：\n",
    "\n",
    "1. 读取预处理好的数据\n",
    "2. 训练\n",
    "3. 完事"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据集路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_data_path = 'data/merged_train_test_seg_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size 82871,test data size 20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Question</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰GL级</td>\n",
       "      <td>方向机 重 助力 泵 方向机 都 换</td>\n",
       "      <td>新 都 换 助力 泵 方向机 换 方向机 带 助力 重 这车 匹配 不 需要 更换 部件 问...</td>\n",
       "      <td>随时 联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰M级</td>\n",
       "      <td>奔驰 ML500 排气 凸轮轴 调节 错误</td>\n",
       "      <td>有没有 电脑 检测 故障 代码 有发 一下 发动机 之前 亮 故障 灯 显示 失火 有点 缺...</td>\n",
       "      <td>随时 联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>宝马</td>\n",
       "      <td>宝马X1 进口</td>\n",
       "      <td>2010 款 宝马X1 2011 年 出厂 20 排量 通用 6L45 变速箱 原地 换挡 ...</td>\n",
       "      <td>4 缸 自然 吸气 发动机 N46 先挂 空档 再 挂 档 有没有 闯动 变速箱 油液 位 ...</td>\n",
       "      <td>行驶 没有 顿挫 感觉 原地 换挡 闯动 刹车 踩 重 没有 力 限制 作用 应该 没有 问题</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>牧马人</td>\n",
       "      <td>30V6 发动机 号 位置 照片 最好</td>\n",
       "      <td>右侧 排气管 上方 缸体 上 靠近 变速箱 是不是 号 不 先拓 下来 行车证 下 不是 有...</td>\n",
       "      <td>举起 车辆 左 前轮 缸体 上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰C级</td>\n",
       "      <td>2012 款 奔驰 c180 维修保养 动力 值得 拥有</td>\n",
       "      <td>家庭 用车 入手 维修保养 费用 不高 12 年 180 市场 价钱 现在 想 媳妇 买 属...</td>\n",
       "      <td>家庭 用车 入手 维修保养 价格 还 车况 好 价格合理 入手</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID Brand    Model                                           Question  \\\n",
       "0  Q1    奔驰    奔驰GL级                                 方向机 重 助力 泵 方向机 都 换   \n",
       "1  Q2    奔驰     奔驰M级                              奔驰 ML500 排气 凸轮轴 调节 错误   \n",
       "2  Q3    宝马  宝马X1 进口  2010 款 宝马X1 2011 年 出厂 20 排量 通用 6L45 变速箱 原地 换挡 ...   \n",
       "3  Q4  Jeep      牧马人                                30V6 发动机 号 位置 照片 最好   \n",
       "4  Q5    奔驰     奔驰C级                       2012 款 奔驰 c180 维修保养 动力 值得 拥有   \n",
       "\n",
       "                                            Dialogue  \\\n",
       "0  新 都 换 助力 泵 方向机 换 方向机 带 助力 重 这车 匹配 不 需要 更换 部件 问...   \n",
       "1  有没有 电脑 检测 故障 代码 有发 一下 发动机 之前 亮 故障 灯 显示 失火 有点 缺...   \n",
       "2  4 缸 自然 吸气 发动机 N46 先挂 空档 再 挂 档 有没有 闯动 变速箱 油液 位 ...   \n",
       "3  右侧 排气管 上方 缸体 上 靠近 变速箱 是不是 号 不 先拓 下来 行车证 下 不是 有...   \n",
       "4  家庭 用车 入手 维修保养 费用 不高 12 年 180 市场 价钱 现在 想 媳妇 买 属...   \n",
       "\n",
       "                                            Report  \n",
       "0                                            随时 联系  \n",
       "1                                            随时 联系  \n",
       "2  行驶 没有 顿挫 感觉 原地 换挡 闯动 刹车 踩 重 没有 力 限制 作用 应该 没有 问题  \n",
       "3                                  举起 车辆 左 前轮 缸体 上  \n",
       "4                  家庭 用车 入手 维修保养 价格 还 车况 好 价格合理 入手  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "print('train data size {},test data size {}'.format(len(train_df),len(test_df)))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 模型创建\n",
    "\n",
    "Gensim中 Word2Vec 模型的期望输入是进过分词的句子列表，即是某个二维数组。这里我们暂时使用 Python 内置的数组，不过其在输入数据集较大的情况下会占用大量的 RAM。Gensim 本身只是要求能够迭代的有序句子列表，因此在工程实践中我们可以使用自定义的生成器，只在内存中保存单条语句。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec 参数\n",
    "+ min_count\n",
    "\n",
    "在不同大小的语料集中，我们对于基准词频的需求也是不一样的。譬如在较大的语料集中，我们希望忽略那些只出现过一两次的单词，这里我们就可以通过设置min_count参数进行控制。一般而言，合理的参数值会设置在0~100之间。\n",
    "\n",
    "+ size\n",
    "\n",
    "size参数主要是用来设置神经网络的层数，Word2Vec 中的默认值是设置为100层。更大的层次设置意味着更多的输入数据，不过也能提升整体的准确度，合理的设置范围为 10~数百。\n",
    "\n",
    "+ workers\n",
    "\n",
    "workers参数用于设置并发训练时候的线程数，不过仅当Cython安装的情况下才会起作用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 引入 word2vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "\n",
    "# 引入日志配置\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 16:39:41,459 : INFO : collecting all words and their counts\n",
      "2019-11-17 16:39:41,460 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-17 16:39:41,677 : INFO : PROGRESS: at sentence #10000, processed 928198 words, keeping 41567 word types\n",
      "2019-11-17 16:39:41,892 : INFO : PROGRESS: at sentence #20000, processed 1870800 words, keeping 62216 word types\n",
      "2019-11-17 16:39:42,104 : INFO : PROGRESS: at sentence #30000, processed 2802551 words, keeping 77593 word types\n",
      "2019-11-17 16:39:42,317 : INFO : PROGRESS: at sentence #40000, processed 3706533 words, keeping 90875 word types\n",
      "2019-11-17 16:39:42,541 : INFO : PROGRESS: at sentence #50000, processed 4670345 words, keeping 102969 word types\n",
      "2019-11-17 16:39:42,782 : INFO : PROGRESS: at sentence #60000, processed 5694540 words, keeping 115297 word types\n",
      "2019-11-17 16:39:43,019 : INFO : PROGRESS: at sentence #70000, processed 6741207 words, keeping 127165 word types\n",
      "2019-11-17 16:39:43,233 : INFO : PROGRESS: at sentence #80000, processed 7674447 words, keeping 137269 word types\n",
      "2019-11-17 16:39:43,435 : INFO : PROGRESS: at sentence #90000, processed 8523641 words, keeping 146973 word types\n",
      "2019-11-17 16:39:43,629 : INFO : PROGRESS: at sentence #100000, processed 9364114 words, keeping 155806 word types\n",
      "2019-11-17 16:39:43,692 : INFO : collected 158323 word types from a corpus of 9610735 raw words and 102871 sentences\n",
      "2019-11-17 16:39:43,693 : INFO : Loading a fresh vocabulary\n",
      "2019-11-17 16:39:43,949 : INFO : effective_min_count=0 retains 158323 unique words (100% of original 158323, drops 0)\n",
      "2019-11-17 16:39:43,949 : INFO : effective_min_count=0 leaves 9610735 word corpus (100% of original 9610735, drops 0)\n",
      "2019-11-17 16:39:44,233 : INFO : deleting the raw counts dictionary of 158323 items\n",
      "2019-11-17 16:39:44,235 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2019-11-17 16:39:44,235 : INFO : downsampling leaves estimated 8682688 word corpus (90.3% of prior 9610735)\n",
      "2019-11-17 16:39:44,467 : INFO : estimated required memory for 158323 words and 200 dimensions: 332478300 bytes\n",
      "2019-11-17 16:39:44,467 : INFO : resetting layer weights\n",
      "2019-11-17 16:39:45,836 : INFO : training model with 8 workers on 158323 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-11-17 16:39:46,844 : INFO : EPOCH 1 - PROGRESS: at 21.54% examples, 1867976 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-17 16:39:47,853 : INFO : EPOCH 1 - PROGRESS: at 44.61% examples, 1906590 words/s, in_qsize 13, out_qsize 2\n",
      "2019-11-17 16:39:48,857 : INFO : EPOCH 1 - PROGRESS: at 65.58% examples, 1932112 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-17 16:39:49,862 : INFO : EPOCH 1 - PROGRESS: at 88.34% examples, 1930596 words/s, in_qsize 15, out_qsize 1\n",
      "2019-11-17 16:39:50,298 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-17 16:39:50,299 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-17 16:39:50,304 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-17 16:39:50,304 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-17 16:39:50,312 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-17 16:39:50,313 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-17 16:39:50,314 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-17 16:39:50,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-17 16:39:50,315 : INFO : EPOCH - 1 : training on 9610735 raw words (8682568 effective words) took 4.5s, 1939767 effective words/s\n",
      "2019-11-17 16:39:51,322 : INFO : EPOCH 2 - PROGRESS: at 22.28% examples, 1932131 words/s, in_qsize 15, out_qsize 1\n",
      "2019-11-17 16:39:52,327 : INFO : EPOCH 2 - PROGRESS: at 45.24% examples, 1941664 words/s, in_qsize 14, out_qsize 2\n",
      "2019-11-17 16:39:53,331 : INFO : EPOCH 2 - PROGRESS: at 66.28% examples, 1958308 words/s, in_qsize 14, out_qsize 0\n",
      "2019-11-17 16:39:54,331 : INFO : EPOCH 2 - PROGRESS: at 88.97% examples, 1950654 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-17 16:39:54,743 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-17 16:39:54,746 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-17 16:39:54,748 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-17 16:39:54,753 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-17 16:39:54,754 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-17 16:39:54,754 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-17 16:39:54,756 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-17 16:39:54,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-17 16:39:54,758 : INFO : EPOCH - 2 : training on 9610735 raw words (8682830 effective words) took 4.4s, 1955486 effective words/s\n",
      "2019-11-17 16:39:55,771 : INFO : EPOCH 3 - PROGRESS: at 22.50% examples, 1935800 words/s, in_qsize 14, out_qsize 2\n",
      "2019-11-17 16:39:56,780 : INFO : EPOCH 3 - PROGRESS: at 45.34% examples, 1935772 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-17 16:39:57,783 : INFO : EPOCH 3 - PROGRESS: at 66.05% examples, 1942982 words/s, in_qsize 13, out_qsize 3\n",
      "2019-11-17 16:39:58,784 : INFO : EPOCH 3 - PROGRESS: at 88.68% examples, 1939019 words/s, in_qsize 14, out_qsize 0\n",
      "2019-11-17 16:39:59,206 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-17 16:39:59,210 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-17 16:39:59,216 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-17 16:39:59,219 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-17 16:39:59,224 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-17 16:39:59,225 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-17 16:39:59,226 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-17 16:39:59,227 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-17 16:39:59,227 : INFO : EPOCH - 3 : training on 9610735 raw words (8682599 effective words) took 4.5s, 1943468 effective words/s\n",
      "2019-11-17 16:40:00,233 : INFO : EPOCH 4 - PROGRESS: at 21.87% examples, 1897612 words/s, in_qsize 14, out_qsize 0\n",
      "2019-11-17 16:40:01,238 : INFO : EPOCH 4 - PROGRESS: at 44.89% examples, 1924821 words/s, in_qsize 13, out_qsize 2\n",
      "2019-11-17 16:40:02,254 : INFO : EPOCH 4 - PROGRESS: at 65.79% examples, 1934276 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-17 16:40:03,254 : INFO : EPOCH 4 - PROGRESS: at 88.51% examples, 1934738 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-17 16:40:03,678 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-17 16:40:03,683 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-17 16:40:03,684 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-17 16:40:03,686 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-17 16:40:03,692 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-17 16:40:03,695 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-17 16:40:03,697 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-17 16:40:03,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-17 16:40:03,700 : INFO : EPOCH - 4 : training on 9610735 raw words (8682865 effective words) took 4.5s, 1942351 effective words/s\n",
      "2019-11-17 16:40:04,705 : INFO : EPOCH 5 - PROGRESS: at 21.97% examples, 1908870 words/s, in_qsize 12, out_qsize 3\n",
      "2019-11-17 16:40:05,713 : INFO : EPOCH 5 - PROGRESS: at 45.25% examples, 1940517 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-17 16:40:06,722 : INFO : EPOCH 5 - PROGRESS: at 66.14% examples, 1948714 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-17 16:40:07,732 : INFO : EPOCH 5 - PROGRESS: at 88.63% examples, 1934456 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-17 16:40:08,149 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-17 16:40:08,153 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 16:40:08,159 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-17 16:40:08,160 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-17 16:40:08,160 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-17 16:40:08,161 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-17 16:40:08,167 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-17 16:40:08,170 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-17 16:40:08,170 : INFO : EPOCH - 5 : training on 9610735 raw words (8683775 effective words) took 4.5s, 1943460 effective words/s\n",
      "2019-11-17 16:40:08,171 : INFO : training on a 48053675 raw words (43414637 effective words) took 22.3s, 1943881 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(LineSentence(merger_data_path), workers=8,min_count=0,size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查找最近的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('海马', 0.8893340826034546),\n",
       " ('东南', 0.876111626625061),\n",
       " ('二代', 0.8668296337127686),\n",
       " ('铃木', 0.8638443946838379),\n",
       " ('名爵', 0.8610075116157532),\n",
       " ('猎豹', 0.856071412563324),\n",
       " ('东风风行', 0.8480671048164368),\n",
       " ('江淮', 0.846108615398407),\n",
       " ('瑞虎5', 0.8452643752098083),\n",
       " ('东风', 0.8447585701942444)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['奇瑞'],topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path='data/wv/word2vec.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 16:42:40,274 : INFO : saving Word2Vec object under data/wv/word2vec.model, separately None\n",
      "2019-11-17 16:42:40,277 : INFO : storing np array 'vectors' to data/wv/word2vec.model.wv.vectors.npy\n",
      "2019-11-17 16:42:40,404 : INFO : not storing attribute vectors_norm\n",
      "2019-11-17 16:42:40,408 : INFO : storing np array 'syn1neg' to data/wv/word2vec.model.trainables.syn1neg.npy\n",
      "2019-11-17 16:42:40,537 : INFO : not storing attribute cum_table\n",
      "2019-11-17 16:42:40,760 : INFO : saved data/wv/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "model.save(save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 16:43:21,044 : INFO : loading Word2Vec object from data/wv/word2vec.model\n",
      "2019-11-17 16:43:21,262 : INFO : loading wv recursively from data/wv/word2vec.model.wv.* with mmap=None\n",
      "2019-11-17 16:43:21,262 : INFO : loading vectors from data/wv/word2vec.model.wv.vectors.npy with mmap=None\n",
      "2019-11-17 16:43:21,292 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-17 16:43:21,293 : INFO : loading vocabulary recursively from data/wv/word2vec.model.vocabulary.* with mmap=None\n",
      "2019-11-17 16:43:21,293 : INFO : loading trainables recursively from data/wv/word2vec.model.trainables.* with mmap=None\n",
      "2019-11-17 16:43:21,293 : INFO : loading syn1neg from data/wv/word2vec.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-17 16:43:21,323 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-17 16:43:21,324 : INFO : loaded data/wv/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 16:43:28,803 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('东南', 0.8724187016487122),\n",
       " ('瑞虎', 0.8533821105957031),\n",
       " ('二代', 0.8516823053359985),\n",
       " ('名爵', 0.847603440284729),\n",
       " ('江淮', 0.8443121910095215),\n",
       " ('海马', 0.8403477072715759),\n",
       " ('瑞虎5', 0.8393649458885193),\n",
       " ('东风风行', 0.8331546783447266),\n",
       " ('东风', 0.8330514430999756),\n",
       " ('铃木', 0.8277937769889832)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['奇瑞'],topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://radimrehurek.com/gensim/models/word2vec.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture02",
   "language": "python",
   "name": "lecture02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
