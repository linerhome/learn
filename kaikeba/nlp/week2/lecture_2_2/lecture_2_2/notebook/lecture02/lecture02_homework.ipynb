{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 作业2要求：\n",
    "\n",
    "1. 通过gensim训练词向量\n",
    " + 1.1 利用分词后的项目数据生成训练词向量用的训练数据\n",
    " + 1.2 保存词向量训练数据\n",
    " + 1.3 应用gensim中Word2Vec或Fasttext训练词向量\n",
    " + 1.4 保存训练好的词向量\n",
    "\n",
    "2. 构建embedding_matrix\n",
    "\n",
    "> 读取上步计算词向量和构建的`vocab`词表，以`vocab`中的`index`为`key`值构建`embedding_matrix`\n",
    "\n",
    "`eg: embedding_matrix[i] = [embedding_vector]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_modelk_path='data/wv/word2vec.model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 16:43:21,044 : INFO : loading Word2Vec object from data/wv/word2vec.model\n",
      "2019-11-17 16:43:21,262 : INFO : loading wv recursively from data/wv/word2vec.model.wv.* with mmap=None\n",
      "2019-11-17 16:43:21,262 : INFO : loading vectors from data/wv/word2vec.model.wv.vectors.npy with mmap=None\n",
      "2019-11-17 16:43:21,292 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-17 16:43:21,293 : INFO : loading vocabulary recursively from data/wv/word2vec.model.vocabulary.* with mmap=None\n",
      "2019-11-17 16:43:21,293 : INFO : loading trainables recursively from data/wv/word2vec.model.trainables.* with mmap=None\n",
      "2019-11-17 16:43:21,293 : INFO : loading syn1neg from data/wv/word2vec.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-17 16:43:21,323 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-17 16:43:21,324 : INFO : loaded data/wv/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(save_modelk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 16:43:28,803 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('东南', 0.8724187016487122),\n",
       " ('瑞虎', 0.8533821105957031),\n",
       " ('二代', 0.8516823053359985),\n",
       " ('名爵', 0.847603440284729),\n",
       " ('江淮', 0.8443121910095215),\n",
       " ('海马', 0.8403477072715759),\n",
       " ('瑞虎5', 0.8393649458885193),\n",
       " ('东风风行', 0.8331546783447266),\n",
       " ('东风', 0.8330514430999756),\n",
       " ('铃木', 0.8277937769889832)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['奇瑞'],topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://radimrehurek.com/gensim/models/word2vec.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture02",
   "language": "python",
   "name": "lecture02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
